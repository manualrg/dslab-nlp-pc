{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74d424",
   "metadata": {},
   "source": [
    "# Experiment: Run HPT with GridSearch to build a GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8090030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src import models, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d09fb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_ID = '202507'  # model_version_id\n",
    "SCORE = \"F1\"\n",
    "\n",
    "# Paths\n",
    "path_interim = os.path.join(\"data\", \"interim\")\n",
    "path_experiment1 =  os.path.join(path_interim, \"exp01_hpt_nb\")\n",
    "path_experiment2 =  os.path.join(path_interim, \"exp02_hpt_gbt\")\n",
    "path_model_prod = os.path.join(\"models\", \"prod\")\n",
    "path_model_arch = os.path.join(\"models\", \"archive\")\n",
    "\n",
    "# Input\n",
    "file_train = \"train.csv\"\n",
    "file_test = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_model_prod):\n",
    "    print(f\"Creating the folder: {path_model_prod}\")\n",
    "    os.mkdir(path_model_prod)\n",
    "if not os.path.exists(path_model_arch):\n",
    "    print(f\"Creating the folder: {path_model_arch}\")\n",
    "    os.mkdir(path_model_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504841b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27beda0c",
   "metadata": {},
   "source": [
    "## Train/Test Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_train = os.path.join(path_interim, file_train)\n",
    "\n",
    "df_train = pd.read_csv(path_data_train)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_test = os.path.join(path_interim, file_test)\n",
    "\n",
    "df_test = pd.read_csv(path_data_test)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e29c53",
   "metadata": {},
   "source": [
    "## Experiments results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_summary_exp1 = pd.read_csv(\n",
    "    os.path.join(path_experiment1,\"df_exp_summary.csv\")\n",
    ")\n",
    "df_cv_summary_exp1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aeec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_summary_exp2 = pd.read_csv(\n",
    "     os.path.join(path_experiment2,\"df_exp_summary.csv\")\n",
    ")\n",
    "df_cv_summary_exp2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c7f91",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79822388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_summary_exp1.sort_values(ascending=True, by=\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e407ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_summary_exp2.sort_values(ascending=True, by=\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d313d03",
   "metadata": {},
   "source": [
    "# Champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_summary_exp1.loc[\n",
    "    df_cv_summary_exp1['rank_test_score'] == 1, [\n",
    "        \"mean_test_score\", \"std_test_score\",\n",
    "        \"param_fte__max_df\",\"param_fte__max_features\",\t\"param_fte__min_df\"]  # set the params of your champion model\n",
    "]   # at a tie, you can get the model with : lowest std_test_score and the most simple one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de11db",
   "metadata": {},
   "source": [
    "Go to src/models.py and implement get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_pl = models.get_model(\n",
    "    # Set the champion HPT configuration: ID=11\n",
    "        min_df=3,\n",
    "        max_df=0.5,\n",
    "        max_features=None\n",
    ")\n",
    "\n",
    "X_train = ...\n",
    "y_train = ...\n",
    "\n",
    "X_test = ...\n",
    "y_test = ...\n",
    "\n",
    "skl_pl.fit(X_train, y_train)\n",
    "\n",
    "y_hats_train = skl_pl.predict(...)\n",
    "f1_score_train = f1_score(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_hats_train\n",
    ")\n",
    "\n",
    "y_hats_test = ...\n",
    "f1_score_test = ...\n",
    "\n",
    "\n",
    "print(f\"{f1_score_train=}\")\n",
    "print(f\"{f1_score_test=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f5a85",
   "metadata": {},
   "source": [
    "# Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f95183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "metadata = {\n",
    "    \"score\": SCORE,\n",
    "    \"test_value\": f1_score_test,\n",
    "    \"version_id\": VERSION_ID,\n",
    "    \"exe_dt\": datetime.now().strftime(\"%Y%m%D\"),\n",
    "    \"sklearn\": sklearn.__version__\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "utils.register_model(\n",
    "    skl_pl,\n",
    "    metadata,\n",
    "    VERSION_ID\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec95e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that model is properly stored\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(path_model_prod, \"model.pkl\"), \"rb\") as file:\n",
    "    rd_skl_pl = pickle.load( file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e462e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
