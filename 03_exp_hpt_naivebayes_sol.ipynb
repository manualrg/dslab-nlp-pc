{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74d424",
   "metadata": {},
   "source": [
    "# Experiment: Run HPT with GridSearch to build a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b94901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\parse.py' for module 'urllib.parse': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 2031: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\functools.py' for module 'functools': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 308: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\pydoc_data\\topics.py' for module 'pydoc_data.topics': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 3128: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\re\\_casefix.py' for module 're._casefix': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 911: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\shlex.py' for module 'shlex': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 1482: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from src import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d09fb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3989ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_SEED = 123\n",
    "PCT_TEST = 0.2\n",
    "K_FOLD = 3\n",
    "\n",
    "EXPERIMENT = \"exp01_hpt_nb\"\n",
    "\n",
    "# Paths\n",
    "path_interim = os.path.join(\"data\", \"interim\")\n",
    "path_experiment =  os.path.join(path_interim, EXPERIMENT)\n",
    "\n",
    "# Input\n",
    "file_train = \"train.csv\"\n",
    "\n",
    "# Output\n",
    "file_exp = \"df_exp_summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8cc4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the folder: data\\interim\\exp01_hpt_nb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "utils.create_or_clean_folder(path_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504841b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d924364d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_text</th>\n",
       "      <th>y_is_nf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respuestas coherentes e idénticas ante entrada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gestión de usuarios: Todos los administradores...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Añadir numero de una revista. Para ello debemo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un usuario registrado visualiza la tabla de en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como usuario quiero poder ordenar las listas d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              x_text  y_is_nf\n",
       "0  Respuestas coherentes e idénticas ante entrada...        0\n",
       "1  Gestión de usuarios: Todos los administradores...        0\n",
       "2  Añadir numero de una revista. Para ello debemo...        0\n",
       "3  Un usuario registrado visualiza la tabla de en...        0\n",
       "4  Como usuario quiero poder ordenar las listas d...        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_train = os.path.join(path_interim, file_train)\n",
    "\n",
    "df_train = pd.read_csv(path_data_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f5a85",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41ed75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example='Respuestas coherentes e idénticas ante entradas de audio o texto: Los usuarios tienen la posibilidad de escuchar la respuesta mediante voz, esta ha de ser entendida e idéntica a la respuesta por escrito.'\n",
      "ex_stem=['respuest', 'coherent', 'ident', 'entrad', 'audi', 'text', 'usuari', 'posibil', 'escuch', 'respuest', 'mediant', 'voz', 'ser', 'entend', 'ident', 'respuest', 'escrit']\n"
     ]
    }
   ],
   "source": [
    "# Helper Cell: Tokenization and stemming in Spanish\n",
    "import typing\n",
    "import string\n",
    "\n",
    "\n",
    "def tokenizer_stemmer_es(text) -> typing.List[str]:\n",
    "    stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "    clean_words = [word for word in word_tokenize(text) if word not in string.punctuation and word.lower() not in stopword_es] # list[str]\n",
    "    return [stemmer.stem(word) for word in clean_words]  # list[str]\n",
    "\n",
    "\n",
    "stopwords_es = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "example = df_train.loc[0, \"x_text\"]\n",
    "ex_stem = tokenizer_stemmer_es(example)\n",
    "\n",
    "print(f\"{example=}\")\n",
    "print(f\"{ex_stem=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c4e143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbin_unigrams = CountVectorizer(\n",
    "    strip_accents=\"ascii\",\n",
    "    lowercase=True,\n",
    "    tokenizer=tokenizer_stemmer_es,\n",
    "    ngram_range=(1, 1),\n",
    "    binary=True,\n",
    ")\n",
    "\n",
    "\n",
    "clf_nbber = BernoulliNB()\n",
    "\n",
    "# Create the pipeline\n",
    "skl_pl = Pipeline([\n",
    "    ('fte', tfbin_unigrams),\n",
    "    ('clf', clf_nbber)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6bdfb",
   "metadata": {},
   "source": [
    "# Cross validate the model\n",
    "\n",
    "Use the GridSearchCV object but with only a single configuration,\n",
    "in order to maintain experiments scheme easily comparable.\n",
    "You could also use other CV methods\n",
    "\n",
    "Remember to use always the same number of CV Folds and the same CV metric on \n",
    "every experiment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23df2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-pc\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_search.best_score_=np.float64(0.7630102355407572)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = df_train['x_text']\n",
    "y_train = df_train['y_is_nf']\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'fte__max_features': [64, 128, None],\n",
    "    'fte__max_df': [0.95, 0.5, 0.25],\n",
    "    'fte__min_df': [1, 3],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    skl_pl,\n",
    "    param_grid,\n",
    "    cv=K_FOLD,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"{grid_search.best_score_=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5c3cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fte__max_df</th>\n",
       "      <th>param_fte__max_features</th>\n",
       "      <th>param_fte__min_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>experiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.983928</td>\n",
       "      <td>0.036843</td>\n",
       "      <td>0.814413</td>\n",
       "      <td>0.027580</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': 64,...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>14</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.981797</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>0.783901</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': 64,...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.706063</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>15</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125473</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.791282</td>\n",
       "      <td>0.021634</td>\n",
       "      <td>0.95</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': 128...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.753324</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>6</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.958170</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.795039</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.95</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': 128...</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743732</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>9</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.038421</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.806612</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>0.95</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': Non...</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.095391</td>\n",
       "      <td>18</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.854620</td>\n",
       "      <td>0.092638</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.047484</td>\n",
       "      <td>0.95</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.95, 'fte__max_features': Non...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.753380</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>5</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.832264</td>\n",
       "      <td>0.080353</td>\n",
       "      <td>0.863705</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': 64, ...</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.728790</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>10</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.859736</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>0.936765</td>\n",
       "      <td>0.063601</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': 64, ...</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.728790</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>10</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.927503</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>0.942633</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': 128,...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.763010</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>1</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.999015</td>\n",
       "      <td>0.037303</td>\n",
       "      <td>0.862761</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': 128,...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.760832</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>3</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.979878</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.989575</td>\n",
       "      <td>0.035575</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': None...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.609669</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>16</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.775869</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.936035</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.5, 'fte__max_features': None...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.752707</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>7</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.774689</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>0.840168</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': 64,...</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.728790</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>10</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.872612</td>\n",
       "      <td>0.056388</td>\n",
       "      <td>0.881768</td>\n",
       "      <td>0.039478</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': 64,...</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.728790</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>10</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.786306</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': 128...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.763010</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>1</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.843361</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': 128...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.760832</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>3</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.918125</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.320005</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': Non...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.609669</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>16</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.871485</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>{'fte__max_df': 0.25, 'fte__max_features': Non...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.752707</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>7</td>\n",
       "      <td>exp01_hpt_nb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.983928      0.036843         0.814413        0.027580   \n",
       "1        1.981797      0.075710         0.783901        0.025374   \n",
       "2        2.125473      0.020650         0.791282        0.021634   \n",
       "3        1.958170      0.022857         0.795039        0.035407   \n",
       "4        2.038421      0.007168         0.806612        0.020358   \n",
       "5        1.854620      0.092638         0.870700        0.047484   \n",
       "6        1.832264      0.080353         0.863705        0.016454   \n",
       "7        1.859736      0.036732         0.936765        0.063601   \n",
       "8        1.927503      0.078724         0.942633        0.058768   \n",
       "9        1.999015      0.037303         0.862761        0.032204   \n",
       "10       1.979878      0.016909         0.989575        0.035575   \n",
       "11       1.775869      0.006170         0.936035        0.016712   \n",
       "12       1.774689      0.044286         0.840168        0.011125   \n",
       "13       1.872612      0.056388         0.881768        0.039478   \n",
       "14       1.786306      0.081288         0.902533        0.048165   \n",
       "15       1.843361      0.075904         0.818915        0.031073   \n",
       "16       0.918125      0.011018         0.320005        0.008868   \n",
       "17       0.871485      0.029433         0.303350        0.012006   \n",
       "\n",
       "    param_fte__max_df param_fte__max_features  param_fte__min_df  \\\n",
       "0                0.95                      64                  1   \n",
       "1                0.95                      64                  3   \n",
       "2                0.95                     128                  1   \n",
       "3                0.95                     128                  3   \n",
       "4                0.95                    None                  1   \n",
       "5                0.95                    None                  3   \n",
       "6                0.50                      64                  1   \n",
       "7                0.50                      64                  3   \n",
       "8                0.50                     128                  1   \n",
       "9                0.50                     128                  3   \n",
       "10               0.50                    None                  1   \n",
       "11               0.50                    None                  3   \n",
       "12               0.25                      64                  1   \n",
       "13               0.25                      64                  3   \n",
       "14               0.25                     128                  1   \n",
       "15               0.25                     128                  3   \n",
       "16               0.25                    None                  1   \n",
       "17               0.25                    None                  3   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'fte__max_df': 0.95, 'fte__max_features': 64,...           0.692308   \n",
       "1   {'fte__max_df': 0.95, 'fte__max_features': 64,...           0.692308   \n",
       "2   {'fte__max_df': 0.95, 'fte__max_features': 128...           0.750000   \n",
       "3   {'fte__max_df': 0.95, 'fte__max_features': 128...           0.734694   \n",
       "4   {'fte__max_df': 0.95, 'fte__max_features': Non...           0.484848   \n",
       "5   {'fte__max_df': 0.95, 'fte__max_features': Non...           0.727273   \n",
       "6   {'fte__max_df': 0.5, 'fte__max_features': 64, ...           0.716981   \n",
       "7   {'fte__max_df': 0.5, 'fte__max_features': 64, ...           0.716981   \n",
       "8   {'fte__max_df': 0.5, 'fte__max_features': 128,...           0.750000   \n",
       "9   {'fte__max_df': 0.5, 'fte__max_features': 128,...           0.750000   \n",
       "10  {'fte__max_df': 0.5, 'fte__max_features': None...           0.529412   \n",
       "11  {'fte__max_df': 0.5, 'fte__max_features': None...           0.711111   \n",
       "12  {'fte__max_df': 0.25, 'fte__max_features': 64,...           0.716981   \n",
       "13  {'fte__max_df': 0.25, 'fte__max_features': 64,...           0.716981   \n",
       "14  {'fte__max_df': 0.25, 'fte__max_features': 128...           0.750000   \n",
       "15  {'fte__max_df': 0.25, 'fte__max_features': 128...           0.750000   \n",
       "16  {'fte__max_df': 0.25, 'fte__max_features': Non...           0.529412   \n",
       "17  {'fte__max_df': 0.25, 'fte__max_features': Non...           0.711111   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.720000           0.720000         0.710769        0.013054   \n",
       "1            0.720000           0.705882         0.706063        0.011306   \n",
       "2            0.769231           0.740741         0.753324        0.011866   \n",
       "3            0.769231           0.727273         0.743732        0.018283   \n",
       "4            0.717949           0.615385         0.606061        0.095391   \n",
       "5            0.769231           0.763636         0.753380        0.018601   \n",
       "6            0.734694           0.734694         0.728790        0.008350   \n",
       "7            0.734694           0.734694         0.728790        0.008350   \n",
       "8            0.754717           0.784314         0.763010        0.015186   \n",
       "9            0.754717           0.777778         0.760832        0.012137   \n",
       "10           0.684211           0.615385         0.609669        0.063325   \n",
       "11           0.769231           0.777778         0.752707        0.029619   \n",
       "12           0.734694           0.734694         0.728790        0.008350   \n",
       "13           0.734694           0.734694         0.728790        0.008350   \n",
       "14           0.754717           0.784314         0.763010        0.015186   \n",
       "15           0.754717           0.777778         0.760832        0.012137   \n",
       "16           0.684211           0.615385         0.609669        0.063325   \n",
       "17           0.769231           0.777778         0.752707        0.029619   \n",
       "\n",
       "    rank_test_score experiment_id  \n",
       "0                14  exp01_hpt_nb  \n",
       "1                15  exp01_hpt_nb  \n",
       "2                 6  exp01_hpt_nb  \n",
       "3                 9  exp01_hpt_nb  \n",
       "4                18  exp01_hpt_nb  \n",
       "5                 5  exp01_hpt_nb  \n",
       "6                10  exp01_hpt_nb  \n",
       "7                10  exp01_hpt_nb  \n",
       "8                 1  exp01_hpt_nb  \n",
       "9                 3  exp01_hpt_nb  \n",
       "10               16  exp01_hpt_nb  \n",
       "11                7  exp01_hpt_nb  \n",
       "12               10  exp01_hpt_nb  \n",
       "13               10  exp01_hpt_nb  \n",
       "14                1  exp01_hpt_nb  \n",
       "15                3  exp01_hpt_nb  \n",
       "16               16  exp01_hpt_nb  \n",
       "17                7  exp01_hpt_nb  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_summary = pd.DataFrame(\n",
    "    grid_search.cv_results_\n",
    ")\n",
    "\n",
    "df_exp_summary[\"experiment_id\"] = EXPERIMENT\n",
    "df_exp_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea411f",
   "metadata": {},
   "source": [
    "# Diagnose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd9b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtm_train.shape=(311, 128)\n"
     ]
    }
   ],
   "source": [
    "# Check DTM dimensions\n",
    "skl_pl_fitted = grid_search.best_estimator_  \n",
    "# Only one model is fit, as only one HPT configuration is passed\n",
    "\n",
    "# Access the CountVectorizer part of the pipeline\n",
    "skl_pl_fte = skl_pl_fitted.named_steps['fte']\n",
    "\n",
    "# Get DTM with transform()\n",
    "dtm_train = skl_pl_fte.transform(X_train)\n",
    "print(f\"{dtm_train.shape=}\")  # columns: Number of terms in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96594931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_train=0.8098159509202454\n"
     ]
    }
   ],
   "source": [
    "# Check training predictions and scoring\n",
    "\n",
    "y_hats_train = skl_pl_fitted.predict(X_train)\n",
    "f1_score_train = f1_score(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_hats_train\n",
    ")\n",
    "\n",
    "print(f\"{f1_score_train=}\")  # Is comparable to CV metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebd41b",
   "metadata": {},
   "source": [
    "# Write Experiments Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cd4404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_summary.to_csv(\n",
    "    os.path.join(path_experiment, file_exp),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# other experiments results and artifacts maybe useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f95183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
