{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74d424",
   "metadata": {},
   "source": [
    "# Experiment: Run HPT with GridSearch to build a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b94901",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import ...\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from src import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d09fb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_SEED = 123\n",
    "PCT_TEST = 0.2\n",
    "K_FOLD = 3\n",
    "\n",
    "EXPERIMENT = \"exp01_hpt_nb\"\n",
    "\n",
    "# Paths\n",
    "path_interim = os.path.join(\"data\", \"interim\")\n",
    "path_experiment =  os.path.join(path_interim, EXPERIMENT)\n",
    "\n",
    "# Input\n",
    "file_train = \"train.csv\"\n",
    "\n",
    "# Output\n",
    "file_exp = \"df_exp_summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "utils.create_or_clean_folder(path_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504841b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_train = os.path.join(path_interim, file_train)\n",
    "\n",
    "df_train = pd....\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f5a85",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ed75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Cell: Tokenization and stemming in Spanish\n",
    "import typing\n",
    "import string\n",
    "\n",
    "\n",
    "def tokenizer_stemmer_es(text) -> typing.List[str]:\n",
    "    stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "    clean_words = [word for word in word_tokenize(text) if word not in string.punctuation and word.lower() not in stopword_es] # list[str]\n",
    "    return [stemmer.stem(word) for word in clean_words]  # list[str]\n",
    "\n",
    "\n",
    "stopwords_es = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "example = df_train.loc[0, \"x_text\"]\n",
    "ex_stem = tokenizer_stemmer_es(example)\n",
    "\n",
    "print(f\"{example=}\")\n",
    "print(f\"{ex_stem=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose appropiate instances of XXXVectorizer and BernoulliXXX\n",
    "tfbin_unigrams = XXXVectorizer(\n",
    "    strip_accents=\"ascii\",\n",
    "    lowercase=True,\n",
    "    tokenizer=tokenizer_stemmer_es,\n",
    "    ngram_range=(1, 1),\n",
    "    binary=True,\n",
    ")\n",
    "\n",
    "\n",
    "clf_nbber = BernoulliXXX()\n",
    "\n",
    "# Create the pipeline\n",
    "skl_pl = Pipeline([\n",
    "    ('fte', tfbin_unigrams),\n",
    "    ('clf', clf_nbber)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6bdfb",
   "metadata": {},
   "source": [
    "# Cross validate the model\n",
    "\n",
    "Use the GridSearchCV object but with only a single configuration,\n",
    "in order to maintain experiments scheme easily comparable.\n",
    "You could also use other CV methods\n",
    "\n",
    "Remember to use always the same number of CV Folds and the same CV metric on \n",
    "every experiment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ...\n",
    "\n",
    "# Change at will\n",
    "param_grid = {\n",
    "    # pipelinestep__parameter: [list of parameters values]\n",
    "    # Check in documentation which parameters are worthly to trial\n",
    "    # and what values do they expect\n",
    "    'fte__max_features': ...,\n",
    "    'fte__max_df': ...,\n",
    "    'fte__min_df': ...,\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    skl_pl,\n",
    "    param_grid,\n",
    "    cv=K_FOLD,  # maintain the same number of folds across the project\n",
    "    scoring='f1',  # maintain the same scoring function (cv metric) across the project\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"{grid_search.best_score_=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_summary = pd.DataFrame(\n",
    "    grid_search.cv_results_\n",
    ")\n",
    "\n",
    "df_exp_summary[\"experiment_id\"] = EXPERIMENT\n",
    "df_exp_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea411f",
   "metadata": {},
   "source": [
    "# Diagnose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DTM dimensions\n",
    "skl_pl_fitted = grid_search.best_estimator_  \n",
    "# Only one model is fit, as only one HPT configuration is passed\n",
    "\n",
    "# Access the CountVectorizer part of the pipeline\n",
    "skl_pl_fte = skl_pl_fitted.named_steps['fte']\n",
    "\n",
    "# Get DTM with transform()\n",
    "dtm_train = ...\n",
    "print(f\"{dtm_train.shape=}\")  # columns: Number of terms in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96594931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training predictions and scoring\n",
    "\n",
    "y_hats_train = ...  # get preds with predict()\n",
    "f1_score_train = f1_score(\n",
    "    y_true=...,\n",
    "    y_pred=...\n",
    ")\n",
    "\n",
    "print(f\"{f1_score_train=}\")  # Is comparable to CV metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebd41b",
   "metadata": {},
   "source": [
    "# Write Experiments Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_summary.to_csv(\n",
    "    os.path.join(path_experiment, file_exp),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# other experiments results and artifacts maybe useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f95183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
