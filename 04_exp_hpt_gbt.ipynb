{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74d424",
   "metadata": {},
   "source": [
    "# Experiment: Run HPT with GridSearch to build a GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27fcbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import XXXVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from src import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d09fb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3989ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_SEED = 123\n",
    "PCT_TEST = 0.2\n",
    "K_FOLD = 3\n",
    "\n",
    "EXPERIMENT = \"exp02_hpt_gbt\"\n",
    "\n",
    "# Paths\n",
    "path_interim = os.path.join(\"data\", \"interim\")\n",
    "path_experiment =  os.path.join(path_interim, EXPERIMENT)\n",
    "\n",
    "# Input\n",
    "file_train = \"train.csv\"\n",
    "\n",
    "\n",
    "# Output\n",
    "file_exp = \"df_exp_summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4437ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the folder: data\\interim\\exp02_hpt_gbt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "utils.create_or_clean_folder(path_experiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504841b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924364d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_text</th>\n",
       "      <th>y_is_nf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respuestas coherentes e idénticas ante entrada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gestión de usuarios: Todos los administradores...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Añadir numero de una revista. Para ello debemo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un usuario registrado visualiza la tabla de en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como usuario quiero poder ordenar las listas d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              x_text  y_is_nf\n",
       "0  Respuestas coherentes e idénticas ante entrada...        0\n",
       "1  Gestión de usuarios: Todos los administradores...        0\n",
       "2  Añadir numero de una revista. Para ello debemo...        0\n",
       "3  Un usuario registrado visualiza la tabla de en...        0\n",
       "4  Como usuario quiero poder ordenar las listas d...        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_train = os.path.join(path_interim, file_train)\n",
    "\n",
    "df_train = pd....\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f5a85",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41ed75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example='Respuestas coherentes e idénticas ante entradas de audio o texto: Los usuarios tienen la posibilidad de escuchar la respuesta mediante voz, esta ha de ser entendida e idéntica a la respuesta por escrito.'\n",
      "ex_stem=['respuest', 'coherent', 'e', 'ident', 'ante', 'entrad', 'de', 'audi', 'o', 'text', 'los', 'usuari', 'tien', 'la', 'posibil', 'de', 'escuch', 'la', 'respuest', 'mediant', 'voz', 'esta', 'ha', 'de', 'ser', 'entend', 'e', 'ident', 'a', 'la', 'respuest', 'por', 'escrit']\n"
     ]
    }
   ],
   "source": [
    "# Helper Cell: Tokenization and stemming in Spanish\n",
    "import typing\n",
    "\n",
    "class SpanishStemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "    def __call__(self, text) -> typing.List[str]:\n",
    "        return [self.stemmer.stem(word) for word in word_tokenize(text) if word not in string.punctuation]\n",
    "\n",
    "# Do not forget to preprocesss stopwords\n",
    "tokenizer_es = SpanishStemTokenizer()\n",
    "stopwords_es = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "stopwords_es_tok = list(set([tokenizer_es(term.lower())[0] for term in stopwords_es]))\n",
    "\n",
    "example = df_train.loc[0, \"x_text\"]\n",
    "ex_stem = tokenizer_es(example)\n",
    "\n",
    "print(f\"{example=}\")\n",
    "print(f\"{ex_stem=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigrams = XXXVectorizer(\n",
    "    strip_accents=\"ascii\",\n",
    "    lowercase=True,\n",
    "    tokenizer=SpanishStemTokenizer(),\n",
    "    stop_words=stopwords_es_tok,\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 1),\n",
    ")\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "    n_estimators=2000,  # Many boosting rounds  so early stoping takes place\n",
    "    validation_fraction=0.2,  # Early stopping\n",
    "    random_state=RND_SEED)\n",
    "\n",
    "# Create the pipeline\n",
    "skl_pl = Pipeline([\n",
    "    ('fte', tfidf_unigrams),\n",
    "    ('clf', clf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6bdfb",
   "metadata": {},
   "source": [
    "# GridSearch\n",
    "\n",
    "GridSearchCV will run a set of Cross Validation experiments for you.\n",
    "It will run for every combination of hiperparameters in the `param_grid`\n",
    "and run a Cross Validation job for each.\n",
    "\n",
    "\n",
    "Remember to use always the same number of CV Folds and the same CV metric on \n",
    "every experiment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23df2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-dl\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-nlp-dl\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['tambi'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_search.best_score_=np.float64(0.7221633085896076)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['x_text']\n",
    "y_train = df_train['y_is_nf']\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'fte__max_features': [64, 128, None],\n",
    "    'fte__max_df': [0.95, 0.5, 0.25],\n",
    "    'fte__min_df': [1, 3],\n",
    "    'clf__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    skl_pl,\n",
    "    param_grid,\n",
    "    cv=K_FOLD,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"{grid_search.best_score_=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5c3cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_fte__max_df</th>\n",
       "      <th>param_fte__max_features</th>\n",
       "      <th>param_fte__min_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>experiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.453087</td>\n",
       "      <td>0.582729</td>\n",
       "      <td>0.370237</td>\n",
       "      <td>0.038653</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'clf__max_depth': 3, 'fte__max_df': 0.25, 'ft...</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>1</td>\n",
       "      <td>exp02_hpt_gbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.789417</td>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'clf__max_depth': 3, 'fte__max_df': 0.5, 'fte...</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>1</td>\n",
       "      <td>exp02_hpt_gbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.747724</td>\n",
       "      <td>0.495518</td>\n",
       "      <td>0.276371</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'clf__max_depth': 3, 'fte__max_df': 0.5, 'fte...</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.717230</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>3</td>\n",
       "      <td>exp02_hpt_gbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.068501</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.369439</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'clf__max_depth': 3, 'fte__max_df': 0.25, 'ft...</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.717230</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>3</td>\n",
       "      <td>exp02_hpt_gbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.000706</td>\n",
       "      <td>0.553049</td>\n",
       "      <td>0.268279</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'clf__max_depth': 3, 'fte__max_df': 0.95, 'ft...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.710579</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>5</td>\n",
       "      <td>exp02_hpt_gbt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "14       8.453087      0.582729         0.370237        0.038653   \n",
       "8        7.789417      0.520585         0.269382        0.024915   \n",
       "9        7.747724      0.495518         0.276371        0.011045   \n",
       "15       9.068501      0.342614         0.369439        0.050795   \n",
       "3        8.000706      0.553049         0.268279        0.014653   \n",
       "\n",
       "    param_clf__max_depth  param_fte__max_df param_fte__max_features  \\\n",
       "14                     3               0.25                     128   \n",
       "8                      3               0.50                     128   \n",
       "9                      3               0.50                     128   \n",
       "15                     3               0.25                     128   \n",
       "3                      3               0.95                     128   \n",
       "\n",
       "    param_fte__min_df                                             params  \\\n",
       "14                  1  {'clf__max_depth': 3, 'fte__max_df': 0.25, 'ft...   \n",
       "8                   1  {'clf__max_depth': 3, 'fte__max_df': 0.5, 'fte...   \n",
       "9                   3  {'clf__max_depth': 3, 'fte__max_df': 0.5, 'fte...   \n",
       "15                  3  {'clf__max_depth': 3, 'fte__max_df': 0.25, 'ft...   \n",
       "3                   3  {'clf__max_depth': 3, 'fte__max_df': 0.95, 'ft...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "14           0.731707           0.739130           0.695652         0.722163   \n",
       "8            0.731707           0.739130           0.695652         0.722163   \n",
       "9            0.731707           0.739130           0.680851         0.717230   \n",
       "15           0.731707           0.739130           0.680851         0.717230   \n",
       "3            0.700000           0.723404           0.708333         0.710579   \n",
       "\n",
       "    std_test_score  rank_test_score  experiment_id  \n",
       "14        0.018990                1  exp02_hpt_gbt  \n",
       "8         0.018990                1  exp02_hpt_gbt  \n",
       "9         0.025901                3  exp02_hpt_gbt  \n",
       "15        0.025901                3  exp02_hpt_gbt  \n",
       "3         0.009686                5  exp02_hpt_gbt  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_summary = pd.DataFrame(\n",
    "    grid_search.cv_results_\n",
    ")\n",
    "\n",
    "df_exp_summary[\"experiment_id\"] = EXPERIMENT\n",
    "df_exp_summary.sort_values(ascending=True, by=\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea411f",
   "metadata": {},
   "source": [
    "# Diagnose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd9b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtm_train.shape=(311, 128)\n"
     ]
    }
   ],
   "source": [
    "# Check DTM dimensions\n",
    "skl_pl_fitted = grid_search.best_estimator_  \n",
    "\n",
    "# Access the Vectorizer part of the pipeline\n",
    "skl_pl_fte = skl_pl_fitted.named_steps['fte']\n",
    "\n",
    "# Get DTM with transform()\n",
    "dtm_train = skl_pl_fte.transform(X_train)\n",
    "print(f\"{dtm_train.shape=}\")  # columns: Number of terms in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96594931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_train=1.0\n"
     ]
    }
   ],
   "source": [
    "# Check training predictions and scoring\n",
    "\n",
    "y_hats_train = skl_pl_fitted.predict(X_train)\n",
    "f1_score_train = f1_score(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_hats_train\n",
    ")\n",
    "\n",
    "print(f\"{f1_score_train=}\")  # Is comparable to CV metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e993f0c",
   "metadata": {},
   "source": [
    "# Write Experiments Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f95183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_summary.to_csv(\n",
    "    os.path.join(path_experiment, file_exp),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# other experiments results and artifacts maybe useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90c609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
